import pandas as pd
import numpy as np
import os, ta
from sklearn.preprocessing import MinMaxScaler

INPUT_FILE = 'forex_data/yahoo_EURUSD=X_1h.csv'
OUTPUT_FOLDER = 'forex_preprocessed'
os.makedirs(OUTPUT_FOLDER, exist_ok=True)

df = pd.read_csv(INPUT_FILE, parse_dates=['Datetime'])
df.set_index('Datetime', inplace=True)
print("âœ… Original Data Loaded:")
print(df.head())

df = df.dropna()
df = df[~df.index.duplicated(keep='first')]
df = df[pd.to_numeric(df['Close'], errors='coerce').notnull()]

for col in ['Open', 'High', 'Low', 'Close', 'Volume']:
    df[col] = pd.to_numeric(df[col], errors='coerce')

print("\nâœ… Cleaned Numeric Data:")
print(df.head())

df['rsi'] = ta.momentum.RSIIndicator(df['Close']).rsi()
macd = ta.trend.MACD(df['Close'])
df['macd'] = macd.macd()
df['macd_signal'] = macd.macd_signal()

bollinger = ta.volatility.BollingerBands(df['Close'])
df['bollinger_h'] = bollinger.bollinger_hband()
df['bollinger_l'] = bollinger.bollinger_lband()

df['atr'] = ta.volatility.AverageTrueRange(df['High'], df['Low'], df['Close']).average_true_range()
df['sma_50'] = ta.trend.SMAIndicator(df['Close'], window=50).sma_indicator()
df['sma_200'] = ta.trend.SMAIndicator(df['Close'], window=200).sma_indicator()

print("\nâœ… Technical Indicators Added:")
print(df[['rsi', 'macd', 'bollinger_h', 'atr']].tail())

for lag in range(1, 6):
    df[f'close_lag_{lag}'] = df['Close'].shift(lag)
print("\nâœ… Lagged Features Added:")
print(df[[f'close_lag_{i}' for i in range(1, 6)]].tail())

scaler = MinMaxScaler()
cols_to_normalize = ['Open', 'High', 'Low', 'Close', 'Volume', 'rsi', 'macd', 'macd_signal', 
                     'bollinger_h', 'bollinger_l', 'atr', 'sma_50', 'sma_200'] + \
                    [f'close_lag_{i}' for i in range(1, 6)]

df[cols_to_normalize] = scaler.fit_transform(df[cols_to_normalize])

print("\nâœ… Normalized Data Sample:")
print(df[cols_to_normalize].head())

pair_name = os.path.basename(INPUT_FILE).replace('.csv', '').replace('yahoo_', '').replace('alpha_', '')
out_file = os.path.join(OUTPUT_FOLDER, f'{pair_name}_preprocessed.csv')
df.dropna().to_csv(out_file)

print(f"\nðŸŽ‰ Preprocessed data saved to '{out_file}'")














######################                         v4 backtest 
import pandas as pd
import numpy as np
from sklearn.base import clone 
import joblib
import os
import matplotlib.pyplot as plt
import seaborn as sns
import logging
from tqdm import tqdm
import warnings
from sklearn.metrics import (accuracy_score, classification_report, 
                             confusion_matrix, f1_score, precision_score, recall_score, roc_auc_score)

# --- CONFIGURATION ---
PROCESSED_DATA_PATH = os.path.join('forex_preprocessed', 'finalfeature.csv') # From app_py_v4.py
MODEL_STORAGE_PATH = 'forex_models' # Where models are saved by ml_pipeline_py_v4.py
MODEL_TO_LOAD_FILENAME = 'best_trading_model.pkl' # Model to load for backtesting

# This is the name of the target column AS IT EXISTS in finalfeature.csv (generated by app_py_v4.py)
TARGET_COL_NAME_FROM_DATA = 'Target' 

# This is the name of the column in finalfeature.csv that holds the original price (e.g., 'Close')
# It's used to calculate actual profit/loss for the strategy.
PRICE_COL_FOR_RETURNS_CALC = 'Close'  

# CRITICAL: This MUST be consistent with CONFIG_FUTURE_PERIOD in app_py_v4.py and ml_pipeline_py_v4.py
# It defines the prediction horizon of the loaded model.
# The 'future_price_for_returns' column in backtest results will be based on this.
CONFIG_FUTURE_PERIOD = 2 

# Backtesting Specific Parameters
WALK_FORWARD_STEP_SIZE = 20      # How often to re-train in walk-forward (e.g., every 20 periods)
ROLLING_WINDOW_TRAIN_SIZE = 500  # Size of the training data window for rolling backtest
MIN_SAMPLES_FOR_ROLLING_TRAIN = 250 # Min samples for each training window in rolling backtest
MIN_SAMPLES_FOR_WALK_FORWARD_INITIAL_TRAIN = 300 # Min samples for initial training in walk-forward

# Strategy and Cost Parameters
DEFAULT_CONFIDENCE_THRESHOLD = 0.55 # e.g., only trade if prob > 0.55 or < (1-0.55)
# Simulate transaction costs (these are examples, adjust based on your broker/instrument)
COMMISSION_PER_TRADE_USD = 0.0 # Example: 1 USD per trade (adjust currency if needed)
SLIPPAGE_PIPS = 0.5            # Example: 0.5 pips slippage
PIP_VALUE_EURUSD_1_LOT = 10    # For a standard lot of EURUSD, 1 pip is typically $10
LOT_SIZE_FOR_COST_CALC = 0.01  # Example: trading 0.01 lots for cost calculation
# Note: A full cost model would also need the pair's pip decimal places. Assuming 4 for EURUSD.

# Logging and Output
BACKTEST_OUTPUT_DIR = 'forex_backtest_results'
os.makedirs(BACKTEST_OUTPUT_DIR, exist_ok=True)

warnings.filterwarnings('ignore', category=UserWarning) 
warnings.filterwarnings('ignore', category=FutureWarning) 
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def calculate_transaction_cost(pip_value_per_lot, lot_size, slippage_pips, commission_usd):
    """Calculates total transaction cost for one side of a trade."""
    slippage_cost = slippage_pips * pip_value_per_lot * lot_size
    total_cost = slippage_cost + commission_usd
    return total_cost

TRANSACTION_COST_PER_TRADE = calculate_transaction_cost(
    PIP_VALUE_EURUSD_1_LOT, LOT_SIZE_FOR_COST_CALC, SLIPPAGE_PIPS, COMMISSION_PER_TRADE_USD
)
logger.info(f"Calculated Transaction Cost Per Trade (entry/exit combined would be 2x): ${TRANSACTION_COST_PER_TRADE:.2f}")


def load_data_and_model(data_filepath, model_directory, model_filename_to_load):
    """Loads preprocessed data and the trained model."""
    logger.info(f"Loading preprocessed data from: {data_filepath}")
    if not os.path.exists(data_filepath):
        raise FileNotFoundError(f"Data file not found: {data_filepath}")
    data = pd.read_csv(data_filepath)
    if 'Datetime' in data.columns: # Attempt to parse Datetime for plotting
        data['Datetime'] = pd.to_datetime(data['Datetime'], errors='coerce')
    logger.info(f"Data loaded. Shape: {data.shape}")
    
    model_full_path = os.path.join(model_directory, model_filename_to_load)
    logger.info(f"Loading trained model from: {model_full_path}")
    if not os.path.exists(model_full_path):
        raise FileNotFoundError(f"Model file not found: {model_full_path}. Run ml_pipeline_py_v4.py first.")
    trained_model_object = joblib.load(model_full_path)
    logger.info(f"Model loaded: {type(trained_model_object)}")
    return data, trained_model_object

def prepare_backtest_data(original_data, model_target_col, price_col_for_returns, 
                          model_pred_horizon, min_data_len_needed, loaded_model_instance):
    """
    Prepares X, y for backtesting. Crucially, it re-creates 'future_price_for_returns'
    for calculating strategy returns, aligned with the model's prediction horizon.
    """
    logger.info(f"Preparing data for backtest (Model Horizon: {model_pred_horizon} periods)...")
    if model_target_col not in original_data.columns:
        raise ValueError(f"Model's target column '{model_target_col}' not found in data.")
    if price_col_for_returns not in original_data.columns:
        raise ValueError(f"Price column '{price_col_for_returns}' for returns not found.")

    backtest_df = original_data.copy()
    backtest_df['future_price_for_returns'] = backtest_df[price_col_for_returns].shift(-model_pred_horizon)
    y_actual_model_target = backtest_df[model_target_col] # This is what the model was trained to predict

    backtest_df.dropna(subset=['future_price_for_returns', model_target_col], inplace=True)
    y_actual_model_target = y_actual_model_target[backtest_df.index] 
    
    if len(backtest_df) < min_data_len_needed:
        raise ValueError(f"Not enough data after processing. Need {min_data_len_needed}, got {len(backtest_df)}")

    # Get feature names from the loaded model to ensure consistency
    model_features = []
    if hasattr(loaded_model_instance, 'feature_names_in_'): model_features = list(loaded_model_instance.feature_names_in_)
    elif hasattr(loaded_model_instance, 'feature_name_'): model_features = list(loaded_model_instance.feature_name_) # LGBM
    
    if not model_features:
        logger.warning("Could not automatically get feature names from model. Inferring. THIS IS RISKY.")
        # Fallback: use all columns except target, price, future_price, datetime related
        excluded_cols = [model_target_col, 'future_price_for_returns', price_col_for_returns, 
                         'Datetime', 'Date', 'Time', 'Datetime_str']
        model_features = [col for col in backtest_df.columns if col not in excluded_cols and pd.api.types.is_numeric_dtype(backtest_df[col])]

    missing_in_data = [mf for mf in model_features if mf not in backtest_df.columns]
    if missing_in_data:
        raise ValueError(f"Features expected by model are missing from data: {missing_in_data}")
    
    X_features_for_backtest = backtest_df[model_features].copy()
    if X_features_for_backtest.isnull().any().any():
        logger.warning("NaNs found in X_features_for_backtest. Filling with 0. Review app_py_v4.py."); X_features_for_backtest.fillna(0, inplace=True)
    
    logger.info(f"Backtest data prepared. X shape: {X_features_for_backtest.shape}, y (model target) shape: {y_actual_model_target.shape}")
    logger.info(f"Using {len(model_features)} features for backtesting (from loaded model): {model_features[:5]}...")
    return backtest_df, X_features_for_backtest, y_actual_model_target


def rolling_backtest_simulation(model_template_object, full_backtest_data, X_model_features, y_model_target,
                                train_window_size, retrain_step_size, min_train_samples_in_window,
                                price_col_name, future_price_col_name, 
                                trade_confidence_thresh, cost_per_trade_usd):
    logger.info(f"Starting Rolling Backtest Simulation: Window={train_window_size}, Step={retrain_step_size}, Confidence={trade_confidence_thresh}, Cost=${cost_per_trade_usd:.2f}")
    trade_log = []
    
    num_iterations = (len(X_model_features) - train_window_size) // retrain_step_size + 1
    if num_iterations <= 0:
        raise ValueError(f"Data too short for rolling backtest. Needs > {train_window_size + retrain_step_size} samples.")

    with tqdm(total=num_iterations, desc="Rolling Backtest Simulation") as pbar:
        for i in range(0, len(X_model_features) - train_window_size + 1, retrain_step_size):
            train_start = i
            train_end = i + train_window_size
            predict_start = train_end
            predict_end = min(train_end + retrain_step_size, len(X_model_features))

            if predict_start >= predict_end: break # No more data to predict

            X_train_fold, y_train_fold = X_model_features.iloc[train_start:train_end], y_model_target.iloc[train_start:train_end]
            X_predict_fold, y_actual_target_fold = X_model_features.iloc[predict_start:predict_end], y_model_target.iloc[predict_start:predict_end]
            
            current_prices_fold = full_backtest_data[price_col_name].iloc[predict_start:predict_end]
            future_prices_fold = full_backtest_data[future_price_col_name].iloc[predict_start:predict_end]
            timestamps_fold = full_backtest_data['Datetime'].iloc[predict_start:predict_end] if 'Datetime' in full_backtest_data else X_predict_fold.index

            if len(X_train_fold) < min_train_samples_in_window or X_predict_fold.empty:
                pbar.update(1); continue
            
            current_model_instance = clone(model_template_object) # Fresh model for this training window
            try:
                current_model_instance.fit(X_train_fold, y_train_fold)
                predictions_signal = current_model_instance.predict(X_predict_fold)
                predictions_proba = current_model_instance.predict_proba(X_predict_fold)[:, 1] # Probability of class 1 (UP)
                
                for k in range(len(X_predict_fold)):
                    signal = predictions_signal[k]
                    proba_up = predictions_proba[k]
                    actual_target = y_actual_target_fold.iloc[k]
                    current_price = current_prices_fold.iloc[k]
                    actual_future_price = future_prices_fold.iloc[k]
                    timestamp = timestamps_fold.iloc[k]

                    # Basic Strategy Logic with Confidence Threshold
                    trade_action = 0 # 0: No trade, 1: Long, -1: Short
                    if signal == 1 and proba_up >= trade_confidence_thresh: # Predict UP with confidence
                        trade_action = 1 
                    elif signal == 0 and (1 - proba_up) >= trade_confidence_thresh: # Predict DOWN with confidence
                        trade_action = -1
                    
                    # Calculate P&L if a trade is taken
                    gross_pnl_points = 0
                    if trade_action == 1: # Long
                        gross_pnl_points = actual_future_price - current_price
                    elif trade_action == -1: # Short
                        gross_pnl_points = current_price - actual_future_price
                    
                    # Assuming 1 unit of asset for P&L points. For % P&L: (gross_pnl_points / current_price)
                    # For Forex, P&L in USD = pips * pip_value_per_lot * lot_size
                    # Here, we simplify by directly using price difference.
                    # A more accurate P&L would convert points to currency based on pair & lot size.
                    
                    # Net P&L after costs (if trade occurred)
                    net_pnl_points = gross_pnl_points
                    if trade_action != 0:
                        # Convert cost_per_trade_usd to price points. This is tricky without pip size.
                        # For simplicity, let's assume cost_per_trade_usd is already in terms of price points for now.
                        # A better way: calculate percentage cost relative to price.
                        # Cost as percentage of price: (cost_per_trade_usd * 2) / current_price (for entry & exit)
                        # This is a simplification. True cost modeling is complex.
                        net_pnl_points -= (cost_per_trade_usd * 2 / current_price) * current_price # Rough conversion
                        # Or, if you define cost in pips, convert pips to price points.

                    trade_log.append({
                        'timestamp': timestamp, 'signal': signal, 'proba_up': proba_up,
                        'actual_target': actual_target, 'trade_action': trade_action,
                        'current_price': current_price, 'future_price': actual_future_price,
                        'gross_pnl_points': gross_pnl_points, 'net_pnl_points': net_pnl_points,
                        'train_window': f"{train_start}-{train_end}"
                    })
            except Exception as e: logger.warning(f"Rolling backtest iter failed: {e}")
            pbar.update(1)
    
    if not trade_log: return pd.DataFrame()
    return pd.DataFrame(trade_log)

def analyze_trade_log(trade_log_df, output_dir, initial_capital=10000, risk_per_trade_fraction=0.01):
    """Analyzes the trade log from the backtest simulation."""
    if trade_log_df.empty: logger.warning("Trade log is empty. Skipping analysis."); return

    logger.info("Analyzing trade log...")
    
    # Calculate returns based on net_pnl_points and current_price for trades taken
    # This assumes net_pnl_points is the absolute price change.
    trade_log_df['strategy_return_pct'] = 0.0
    traded_mask = trade_log_df['trade_action'] != 0
    # For percentage return: (net_pnl_points / current_price)
    # This is a simplified way. A proper calculation would use lot size and leverage.
    trade_log_df.loc[traded_mask, 'strategy_return_pct'] = \
        (trade_log_df.loc[traded_mask, 'net_pnl_points'] / trade_log_df.loc[traded_mask, 'current_price'])

    # Filter for actual trades
    actual_trades_df = trade_log_df[trade_log_df['trade_action'] != 0].copy()
    if actual_trades_df.empty: logger.warning("No actual trades taken in simulation."); return

    total_trades = len(actual_trades_df)
    winning_trades = actual_trades_df[actual_trades_df['net_pnl_points'] > 0].shape[0]
    win_rate = (winning_trades / total_trades) * 100 if total_trades > 0 else 0
    
    sum_profit_points = actual_trades_df[actual_trades_df['net_pnl_points'] > 0]['net_pnl_points'].sum()
    sum_loss_points = abs(actual_trades_df[actual_trades_df['net_pnl_points'] < 0]['net_pnl_points'].sum())
    profit_factor = sum_profit_points / sum_loss_points if sum_loss_points > 0 else np.inf
    
    avg_win_points = actual_trades_df[actual_trades_df['net_pnl_points'] > 0]['net_pnl_points'].mean()
    avg_loss_points = abs(actual_trades_df[actual_trades_df['net_pnl_points'] < 0]['net_pnl_points'].mean())
    avg_rr_ratio = avg_win_points / avg_loss_points if avg_loss_points > 0 else np.inf

    logger.info("\n--- Strategy Performance (Based on Simulated Trades) ---")
    logger.info(f"Total Trades Taken: {total_trades}, Win Rate: {win_rate:.2f}%")
    logger.info(f"Profit Factor (Points): {profit_factor:.2f}, Avg Win/Loss Ratio (Points): {avg_rr_ratio:.2f}")
    logger.info(f"Sum Profit (Points): {sum_profit_points:.4f}, Sum Loss (Points): {sum_loss_points:.4f}")

    # Equity Curve (Simplified: assumes reinvesting all profits/losses proportionally)
    # This is a conceptual equity curve. Real equity depends on position sizing.
    actual_trades_df['cumulative_return_pct'] = (1 + actual_trades_df['strategy_return_pct']).cumprod() - 1
    
    plt.figure(figsize=(14, 7))
    plot_idx = pd.to_datetime(actual_trades_df['timestamp'], errors='coerce')
    plot_idx_label = 'Time' if pd.api.types.is_datetime64_any_dtype(plot_idx) else 'Trade Number'
    if not pd.api.types.is_datetime64_any_dtype(plot_idx): plot_idx = actual_trades_df.index

    plt.plot(plot_idx, actual_trades_df['cumulative_return_pct'] * 100)
    plt.title('Conceptual Equity Curve (Cumulative Returns % on Trades Taken)')
    plt.xlabel(plot_idx_label); plt.ylabel('Cumulative Return (%)'); plt.grid(True)
    plt.savefig(os.path.join(output_dir, 'equity_curve_trades.png')); plt.close()
    logger.info(f"Equity curve saved to {os.path.join(output_dir, 'equity_curve_trades.png')}")

    # Model Prediction Quality on Traded Signals
    logger.info("\n--- Model Prediction Quality (on signals that led to trades) ---")
    report = classification_report(actual_trades_df['actual_target'].astype(int), 
                                   (actual_trades_df['signal']).astype(int), zero_division=0) # Use 'signal' not 'trade_action' for model eval
    logger.info(f"\n{report}")
    cm = confusion_matrix(actual_trades_df['actual_target'].astype(int), (actual_trades_df['signal']).astype(int))
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Pred Down', 'Pred Up'], yticklabels=['Actual Down', 'Actual Up'])
    plt.title('Confusion Matrix (Traded Signals)'); plt.ylabel('Actual Target'); plt.xlabel('Predicted Signal')
    plt.savefig(os.path.join(output_dir, 'confusion_matrix_trades.png')); plt.close()
    logger.info(f"Confusion matrix for traded signals saved to {os.path.join(output_dir, 'confusion_matrix_trades.png')}")

    # Save trade log
    version = pd.Timestamp.now().strftime("%Y%m%d_%H%M%S")
    path = os.path.join(output_dir, f"detailed_trade_log_{version}.csv")
    trade_log_df.to_csv(path, index=False)
    logger.info(f"Detailed trade log saved to {path}")


# ======= MAIN EXECUTION =======
if __name__ == "__main__":
    try:
        logger.info("--- Starting Advanced Backtesting Script ---")
        # 1. Load Data and the Pre-trained Model
        full_original_data, trained_model_template = load_data_and_model(
            PROCESSED_DATA_PATH, MODEL_STORAGE_PATH, MODEL_TO_LOAD_FILENAME
        )
        
        # 2. Prepare Data Specifically for Backtesting
        # This aligns features, model's target, and creates 'future_price_for_returns'
        backtest_ready_df, X_for_backtest, y_model_target_for_backtest = prepare_backtest_data(
            full_original_data, 
            model_target_col=TARGET_COL_NAME_FROM_DATA,
            price_col_for_returns=PRICE_COL_FOR_RETURNS_CALC,
            model_pred_horizon=CONFIG_FUTURE_PERIOD,
            min_data_len_needed=ROLLING_WINDOW_TRAIN_SIZE + WALK_FORWARD_STEP_SIZE, # Ensure enough for at least one roll
            loaded_model_instance=trained_model_template
        )
        
        # 3. Perform Rolling Backtest Simulation
        # This is the core of the strategy simulation.
        if len(X_for_backtest) > ROLLING_WINDOW_TRAIN_SIZE + WALK_FORWARD_STEP_SIZE :
            simulated_trades_log_df = rolling_backtest_simulation(
                trained_model_template, # Pass the loaded model as a template to be cloned and re-fitted
                backtest_ready_df,      # Contains prices needed for P&L
                X_for_backtest, 
                y_model_target_for_backtest, # The actual target the model was trained on
                train_window_size=ROLLING_WINDOW_TRAIN_SIZE,
                retrain_step_size=WALK_FORWARD_STEP_SIZE, 
                min_train_samples_in_window=MIN_SAMPLES_FOR_ROLLING_TRAIN,
                price_col_name=PRICE_COL_FOR_RETURNS_CALC,
                future_price_col_name='future_price_for_returns',
                trade_confidence_thresh=DEFAULT_CONFIDENCE_THRESHOLD,
                cost_per_trade_usd=TRANSACTION_COST_PER_TRADE 
            )
            
            # 4. Analyze and Report Backtest Simulation Results
            if not simulated_trades_log_df.empty:
                analyze_trade_log(simulated_trades_log_df, BACKTEST_OUTPUT_DIR)
            else:
                logger.info("Rolling backtest simulation did not produce any trades. Skipping analysis.")
        else:
            logger.warning("Skipping Rolling Backtest Simulation due to insufficient data length relative to window/step size.")

        logger.info("\n--- Key Configuration for this Backtest Run ---")
        logger.info(f"Data Source: {PROCESSED_DATA_PATH}")
        logger.info(f"Loaded Model: {MODEL_TO_LOAD_FILENAME} (Type: {type(trained_model_template)})")
        logger.info(f"Model's Prediction Horizon (CONFIG_FUTURE_PERIOD): {CONFIG_FUTURE_PERIOD} periods")
        logger.info(f"Price column for returns: '{PRICE_COL_FOR_RETURNS_CALC}'")
        logger.info(f"Rolling Window Size: {ROLLING_WINDOW_TRAIN_SIZE}, Retrain Step: {WALK_FORWARD_STEP_SIZE}")
        logger.info(f"Trade Confidence Threshold: {DEFAULT_CONFIDENCE_THRESHOLD}, Cost Per Trade (single side): ${TRANSACTION_COST_PER_TRADE:.2f}")
        logger.info("-------------------------------------------------")
        logger.info("Backtesting process completed.")
        
    except FileNotFoundError as fnf_err: logger.error(f"CRITICAL FILE ERROR: {str(fnf_err)}")
    except ValueError as val_err: logger.error(f"CRITICAL VALIDATION ERROR: {str(val_err)}")
    except Exception as e: logger.error(f"Main backtesting process failed: {str(e)}", exc_info=True)

